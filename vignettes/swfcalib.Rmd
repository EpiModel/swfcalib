---
title: "swfcalib"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{swfcalib}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

`swfcalib` gives a scaffold to make an automated calibration system on a
[Slurm](https://slurm.schedmd.com/) equipped HPC. `swfcalib` relies on
[`slurmworkflow`](https://github.com/EpiModel/slurmworkflow) and a stored
calibration object to chose which step of the calibration to run. This allows
very long calibrations to take place without flooding the `slurm` queue.

For this vignette we will take as an example a simplified version of one of our
epidemic models to showcase `swfcalib` usage.

This model is a network model simulating HIV circulation in a population of 100k
Men who have Sex with Men (MSM).

## The model

A single run of our model locally looks like this:

```r
library(EpiModelHIV)

epistats <- readRDS("data/input/epistats.rds")
netstats <- readRDS("data/input/netstats.rds")
netest   <- readRDS("data/input/netest.rds")

param <- param.net(
  data.frame.params   = read.csv("data/input/params.csv"),
  netstats            = netstats,
  epistats            = epistats
)

init <- init_msm()

control <- control_msm(
  nsteps = 250,
  nsims  = 1,
  ncores = 1
)

# The actual simulation happens here
sim <- netsim(est, param, init, control)
```

In this example, we need to load the `EpiModelHIV` package, to read 4 files
located in a "data/input" folder and to pass 4 parameters to the `netsim`
function.

The result, stored in the `sim` variable is not directly usable by `swfcalib`.

## Calibration parameters and outputs

For this example, we will focus on 9 parameters to calibrate and 9 outputs to
fit to there targets.

There are many more parameters in the model. Some get their values from the
literature, other free parameters to be calibrated are ignored for sake of
simplicity in this example.

### Outputs

The first outputs are the proportion of HIV individuals who are diagnosed (i.e.
    aware of their status).Then is the proportion of HIV diagnosed who started
treatment in less than a month after diagnosis. Finally, the prevalence of
diagnosed HIV in the population is our final output of interest. As our
population is race stratified between, black, hispanic and white, we get three
time the number of outputs.

| Output Name | Description | Target Value|
|-|-|-|
| cc.dx.B | Portion of HIV infected who are diagnosed (black) | 0.847 |
| cc.dx.H | Portion of HIV infected who are diagnosed (hispanic) | 0.818 |
| cc.dx.W | Portion of HIV infected who are diagnosed (white) | 0.862 |
| cc.linked1m.B | Linkage to care within 1 month (black) | 0.829 |
| cc.linked1m.H | Linkage to care within 1 month (hispanic) | 0.898 |
| cc.linked1m.W | Linkage to care within 1 month (white) | 0.881 |
| i.prev.dx.B | HIV diagnosed prevalence (black) | 0.33 |
| i.prev.dx.H | HIV diagnosed prevalence (hispanic) | 0.127 |
| i.prev.dx.W | HIV diagnosed prevalence (W) | 0.084 |

### Parameters

9 parameters will be calibrated to fit the model to these target values. The
weekly probability of being tested for HIV. The weekly probability of starting
treatment if diagnosed for HIV. And a *transmission scaler* which is a parameter
that encompass all the mechanism affecting transmission that are not explicitly
defined in the model.

| Parameter Name | Description |
|-|-|
| hiv.test.rate_1 | Weekly test rate (black) |
| hiv.test.rate_2 | Weekly test rate (hispanic) |
| hiv.test.rate_3 | Weekly test rate (white) |
| tx.init.rate_1 | Weekly treatment start rate (black) |
| tx.init.rate_2 | Weekly treatment start rate (hispanic) |
| tx.init.rate_3 | Weekly treatment start rate (white) |
| hiv.trans.scale_1 | Transmission scaler (black) |
| hiv.trans.scale_2 | Transmission scaler (hispanic) |
| hiv.trans.scale_3 | Transmission scaler (white) |

## Relationship between parameters and outputs

Simply by looking at them, we can see that all the parameters do not relate
to all the outputs in the same way.

The `hiv.test.rate` parameters directly relate to the `cc.dx` outputs
(proportion) of diagnosed. Also, no other parameter in our list would affect
these outcomes. Therefore, we have 3 one to one relationship. For each race, the
test rate will govern the diagnosed proportion.

A similar situation can be described for linkage to care (`cc.linked1m`) and
treatment start rate `tx.init.rate`. (the denominator is the number of diagnosed
individuals, making it independent of `cc.dx`).

The prevalence (`i.prev.dx`), on the other hand, depends on all 9 parameters.
The proportion of diagnosed influences the number of treated which then
influences the number of individuals able to transmit. The scalers then affect
directly the transmission for one population. But as they modify the prevalence,
they also indirectly influence the transmission in the other sub populations.

However, once the `hiv.test.rate` and `tx.init.rate` are calibrated and their
values fixed, `i.prev.dx` only depends on the `hiv.trans.scale` parameters.
Reducing a 9 parameters 3 outputs problem into a simpler 3 parameters, 3 outputs
one.

## Calibration structure

Knowing these parameters - outputs relationship, we can define a calibration
structure to minimize the number of simulations required.

A first wave will calibrate simulateanously the 3 `hiv.test.rate` and the
3 `tx.init.rate` parameters. This means that each run of the simulation will
test a value for each of these 6 parameters. This idea is similar [factorial
experiment design](https://en.wikipedia.org/wiki/Factorial_experiment) and is
only possible because of the independance between the parameters and their
respective outcomes.

After these 6 parameters are calibrated (i.e. given fixed and final values),
the `hiv.trans.scale` parameters will be calibrated to fit the `i.prev.dx`
outcomes to their target values.

## Waves and jobs

To express this structure, we need to define calibration *jobs* that are
be run in parallel within several *waves*.

In our example we will have two *waves*, the first one for the `hiv.test.rate`
and `tx.init.rate` parameters and a second for the `hiv.trans.scale` parameters.

### Jobs

Formally, `swfcalib` defines a *job* as a set of *parameters* to be calibrated
by trying to make a set of *outcomes* reach a set of *targets*.

Each *job* needs a function to make the next set of *parameter* proposals to
test as well as a function for checking if the proposals gave sufficiently good
results. This latter function is in charge of stopping the calibration process
for the current job.

### Waves

A *wave* is a set of multiple jobs that can be run in parallel (i.e.
independent from one another).

In practice, `swfcalib` takes the proposals from all the jobs in a wave, combine
them and run one simulation per proposal. If you have a 3 *job wave*, each
making 10 proposal, only 10 simulations will be run. On the evaluation step
each job will only assess the quality of it's own outcomes.

Once all the *jobs* in a *wave* are finished, the system moves to the next one
if any, using the parameters calibrated on the previous ones.

## Implementing the `model` function

Now that we have a good conceptual idea how the calibration will go, we need to
make our code compatible with `swfcalib`.

For the model function it is pretty straightforward. We need a function with
this signature:

```r
model <- function(proposal) {
  # simulation code
  return(results)
}
```

Where `proposal` is an one row `tibble` with each column being a parameter to
calibrate. In our case, `proposal` is a 1 row 9 columns `tibble`.

And `results` is a one row `tibble` where each column is an output for the
calibration process. In this case, `results` must also be a 1 row 9 columns
`tibble`.

Below is the code for our example.

```r
model <- function(proposal) {
  # Load all required elements
  library(EpiModelHIV)
  library(dplyr)

  epistats <- readRDS("data/input/epistats.rds")
  netstats <- readRDS("data/input/netstats.rds")
  netest   <- readRDS("data/input/netest.rds")

  param <- param.net(
    data.frame.params   = read.csv("data/input/params.csv"),
    netstats            = netstats,
    epistats            = epistats
  )

  init <- init_msm()

  control <- control_msm(
    nsteps = 250,
    nsims  = 1,
    ncores = 1
  )

  # Proposal to scenario -------------------------------------------------------
  scenario <- EpiModelHPC::swfcalib_proposal_to_scenario(proposal)
  param_sc <- EpiModel::use_scenario(param, scenario)

  # Run the simulation ---------------------------------------------------------
  sim <- netsim(est, param_sc, init, control)

  # Process the results  -------------------------------------------------------
  results <- as_tibble(sim) |>
    mutate_calibration_targets() |>
    filter(time >= max(time) - 52) |>
    select(
      cc.dx.B, cc.dx.H, cc.dx.W,
      cc.linked1m.B, cc.linked1m.H, cc.linked1m.W,
      i.prev.dx.B, i.prev.dx.H, i.prev.dx.W,
    ) |>
    summarise(across( everything(), ~ mean(.x, na.rm = TRUE)))

  # Return the one row `tibble`
  return(results)
}
```

Several things are of importance here:

1. We call `library` within the function. It is not usual, but we must remember
that this will be run on an `sbatch` job from a clean environment. Therefore,
the function must load all the required libraries and files.
2. We must adapt the `proposal` to be used by the simulation. In this case, a
helper function `swfcalib_proposal_to_scenario` does it. But simply copying the
values from the `proposal` `tibble` works as well.
3. After the simulation, the outputs must be processed to produce a correctly
formatted `tibble`. In this case, we take the mean over the last 52 weeks (1
year) for each of the desired outputs.

As the users of `swfcalib`, we are responsible for the correct output of
`model`.

Also, `model` must be a function that run a single simulation and produce a
single set of `results`. This function will be run in parallel to test several
proposals at once.

## Configuring an `swfcalib` system

`swfcalib` maintain a `calib_object` that store the state of the calibration as
well as all it needs to operate. This object is first defined locally and then
updated on the HPC as the calibration progresses.

This object is an `R` `list` with 3 elements: `state`, `config` and `waves`.

We won't cover `state` now as it is created by `swfcalib` and only edited by it.

### Configuration

`config` is a `list` with the following elements:

- `simulator`: the function to calibration `model` in our case
- `root_directory`: where the system will store itself on the HPC
- `n_sims`: the number of simulations to run in parallel at each iteration
- `max_iteration`: the maximum number of iteration before stopping the
  calibration if a satisfactory state is not found. This is a fail-safe
  mechanism to avoid consuming HPC resources when the calibration does not work.
- `default_proposal`: default values for the calibrated parameters. This fixes
  the values for the parameters that are to be calibrated in later waves. Once
  a job is finished, the calibrated value is stored here and used for the next
  runs

```r
config = list(
  simulator = model,
  root_directory = "data/calib",
  n_sims = n_sims,
  max_iteration = 100,
  default_proposal = dplyr::tibble(
    hiv.test.rate_1 = 0.004123238,
    hiv.test.rate_2 = 0.003771226,
    hiv.test.rate_3 = 0.005956663,
    tx.init.rate_1 = 0.2981623,
    tx.init.rate_2 = 0.3680919,
    tx.init.rate_3 = 0.358254,
    hiv.trans.scale_1 = 2.470962,
    hiv.trans.scale_2 = 0.4247816,
    hiv.trans.scale_3 = 0.3342994
  )
)
```

### Waves

`waves` is a list of *waves*, with each wave being a list of jobs

```r
waves = list(
  wave1 = list(
    job1 = list(),
    job2 = list(),
    job3 = list()
  ),
  wave2 = list(
    job1 = list(),
    job2 = list()
  )
    )
```

## Calibration jobs

A calibration *job* is a `list` with 6 elements:

1. `targets`: the name of the outputs to fit (>= 1)
2. `targets_val`: the target values
3. `params`: the names of the parameters to calibrate (>=1)
4. `initial_proposals`: a `tibble` with the values to be tested for the first
  run of the simulation.
5. `make_next_proposals`: a function that will define which proposals to make
  next
6. `get_result`: a function to define is the calibration is done for this job

We will get into the details of these elements later on.

Below is an example of the *job* for calibrating the `hiv.trans.scale`
parameters using the `i.prev.dx` outputs.

```r
job1 = list(
  targets = paste0("i.prev.dx.", c("B", "H", "W")),
  targets_val = c(0.33, 0.127, 0.09),
  params = paste0("hiv.trans.scale_", 1:3),
  initial_proposals = dplyr::tibble(
    hiv.trans.scale_1 = sample(seq(1, 4, length.out = n_sims)),
    hiv.trans.scale_2 = sample(seq(0.2, 0.6, length.out = n_sims)),
    hiv.trans.scale_3 = sample(seq(0.2, 0.6, length.out = n_sims))
  ),
  make_next_proposals = make_range_proposer(n_sims),
  get_result = determ_trans_end(
    retain_prop = 0.3,
    thresholds = rep(0.02, 3),
    n_enough = 100
  )
)
```

### Complete configuration

Below is the complete `calib_object` defined locally:

```r
n_sims  <- 400

calib_object <- list(
  config = list(
    simulator = model_fun,
    default_proposal = dplyr::tibble(
      hiv.test.rate_1 = 0.004123238,
      hiv.test.rate_2 = 0.003771226,
      hiv.test.rate_3 = 0.005956663,
      tx.init.rate_1 = 0.2981623,
      tx.init.rate_2 = 0.3680919,
      tx.init.rate_3 = 0.358254,
      hiv.trans.scale_1 = 2.470962,
      hiv.trans.scale_2 = 0.4247816,
      hiv.trans.scale_3 = 0.3342994
    ),
    root_directory = "data/calib",
    max_iteration = 100,
    n_sims = n_sims
  ),
  waves = list(
    wave1 = list(
      job1 = list(
        targets = "cc.dx.B",
        targets_val = 0.847,
        params = c("hiv.test.rate_1"), # target: 0.00385
        initial_proposals = dplyr::tibble(
          hiv.test.rate_1 = seq(0.002, 0.006, length.out = n_sims),
          ),
        make_next_proposals = make_shrink_proposer(n_sims),
        get_result = determ_poly_end(0.001, poly_n = 5)
      ),
      job2 = list(
        targets = "cc.dx.H",
        targets_val = 0.818,
        params = c("hiv.test.rate_2"), # target: 0.0038
        initial_proposals = dplyr::tibble(
          hiv.test.rate_2 = seq(0.002, 0.006, length.out = n_sims),
        ),
        make_next_proposals = make_shrink_proposer(n_sims),
        get_result = determ_poly_end(0.001, poly_n = 5)
        ),
      job3 = list(
        targets = "cc.dx.W",
        targets_val = 0.862,
        params = c("hiv.test.rate_3"), # target: 0.0069
        initial_proposals = dplyr::tibble(
          hiv.test.rate_3 = seq(0.004, 0.008, length.out = n_sims),
        ),
        make_next_proposals = make_shrink_proposer(n_sims),
        get_result = determ_poly_end(0.001, poly_n = 5)
        ),
      job4 = list(
        targets = paste0("cc.linked1m.", c("B", "H", "W")),
        targets_val = c(0.829, 0.898, 0.881),
        params = paste0("tx.init.rate_", 1:3),
        initial_proposals = dplyr::tibble(
          tx.init.rate_1 = sample(seq(0.1, 0.5, length.out = n_sims)),
          tx.init.rate_2 = sample(tx.init.rate_1),
          tx.init.rate_3 = sample(tx.init.rate_1),
        ),
        make_next_proposals = make_ind_shrink_proposer(n_sims),
        get_result = determ_ind_poly_end(0.001, poly_n = 3)
      )
    ),
    wave3 = list(
      job1 = list(
        targets = paste0("i.prev.dx.", c("B", "H", "W")),
        targets_val = c(0.33, 0.127, 0.09),
        params = paste0("hiv.trans.scale_", 1:3),
        initial_proposals = dplyr::tibble(
          hiv.trans.scale_1 = sample(seq(1, 4, length.out = n_sims)),
          hiv.trans.scale_2 = sample(seq(0.2, 0.6, length.out = n_sims)),
          hiv.trans.scale_3 = sample(seq(0.2, 0.6, length.out = n_sims))
        ),
        make_next_proposals = make_range_proposer(n_sims),
        get_result = determ_trans_end(
          retain_prop = 0.3,
          thresholds = rep(0.02, 3),
          n_enough = 100
        )
      )
    )
  )
  # state = list() # managed internally
)
```

# TODO #

- put the functions here into swfcalib package
- finish the vignette
  - explain the proposers and checkers
  - explain the swf steps













`swfcalib` allows the calibration of a *model* where a set of *outcomes* are to
be matched specific *targets*. We specify which *outcome* is governed by what
*parameter* in the *calibration object*.

`swfcalib` defines three simple `slurmworkflow` steps:

1. process the *model* runs *outcomes* and choose what to do next
   - if the calibration is complete, go to step 3
   - if not, make new *parameter* proposals and go to step 2
2. run the *model* with each *parameter* proposals and go back to step 1
3. wrap up the calibration, save the accepted set of *parameters* and all the
   results

## Parameters and Outcomes

In `swfcalib`, *model* is a function that takes a 1 row `tibble` of **all** the
parameters and return a 1 row `tibble` of **all** the outcomes.

However, calibrating all parameters at once with all outcomes at once may not be
the most efficient approach, especially when known independence or conditional
independence exists among parameters and outcomes.

In EpiModelHIV models like [this published
one](https://github.com/EpiModel/CombPrevNet), the portion of individuals
infected by HIV that are diagnosed and the portion of diagnosed that are linked
to care are two independent metrics. They are respectively affected by the
HIV test rate and the rate of treatment linkage.

Therefore, we can calibrate these two parameters on the same set of simulations.

On the other hand, the portion of HIV diagnosed that are virally suppressed
depend on the test rate, linkage to care and retention in care. To calibrate this
last one, we can either Calibrate everything at once, 3 parameters and 3 outcomes.
Doing so is quite hard in our models due to the noisy nature of our results.

The other approach is to calibrate them sequentially. A first wave of
calibration tackles the first two in parallel and a second one the third. This
approach convert one hard and long problem to solve into three simple and quick
one.

A word of caution. This method is very efficient but requires a good
understanding of all the processes at hand to ensure the independence of the
parameters. Fortunately, if such independence does not exists, the final
calibration will be visibly off.

## Calibration Waves, Jobs and Iteration

### Job

Formally, `swfcalib` defines a *job* a set of *parameters* to be calibrated by
trying to make a set of *outcomes* reach a set of *targets*.

Each *job* needs a function to make the next set of *parameter* proposals to
test as well as a function checking if the proposals gave sufficiently good
results. This latter function is in charge of stopping the calibration process
for the current job.

### Wave

A *wave* is a set of multiple jobs that can be run in parallel (i.e.
independent from one another).

In practice, `swfcalib` takes the proposals from all the jobs in a wave, combine
them and run one simulation per proposal. If you have a 3 job wave, each making
10 proposal, only 10 simulations will be run. On the evaluation step, each job
will only assess the quality of it's own outcomes.

Once all the jobs in a wave are finished, the system moves to the next one if
any, using the results of the previous ones.

## Data Structures

### Parameter Proposals

A set of parameter proposals is a `tibble` with 3 mandatory columns:

- `.proposals_index`: the index of the proposal for this iteration
- `.wave`: the number of the current wave
- `.iteration`: the number of the current iteration

plus one column per parameter and each row represent a different unique
proposal.

### Outcomes

A set of outcomes is a `tibble` with 3 mandatory columns:

- `.proposals_index`: the index of the proposal for this iteration
- `.wave`: the number of the current wave
- `.iteration`: the number of the current iteration

plus one column per outcome value and each row represent the outcome from a
specific proposal.

### Results

A set of results is the join of proposals and outcomes. It is a `tibble` with

- all parameter columns
- the three mandatory columns `.proposals_index`, `.wave`, `.iteration`
- all outcome columns
